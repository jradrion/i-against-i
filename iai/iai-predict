#!/usr/bin/env python
from iai.imports import *
from iai.helpers import *
from iai.sequenceBatchGenerator import *
from iai.networks import *


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('-d','--projectDir',dest='outDir',help='Directory for all project output. NOTE: the same projectDir must be used for all functions of i-against-i',default=None)
    #parser.add_argument('-d_a','--projectDir_A',dest='outDir_A',help='Directory for all project output for parameter set A. NOTE: the same projectDir must be used for all functions of i-against-i',default=None)
    #parser.add_argument('-d_b','--projectDir_B',dest='outDir_B',help='Directory for all project output for parameter set B. NOTE: the same projectDir must be used for all functions of i-against-i',default=None)
    parser.add_argument('-m','--maxSegSites',dest='maxSegSites',help='All tensors exceeding this length with be trimmed', type=int, default=1000)
    parser.add_argument('-w','--initWeights',dest='weights',help='Path to the initialization weights',default=None)
    parser.add_argument('--nEpochs',dest='nEpochs',help='Maximum number of epochs to train (EarlyStopping is implemented for validation accuracy)', type=int, default=1000)
    parser.add_argument('--nValSteps',dest='nValSteps',help='Number of validation steps', type=int, default=20)
    parser.add_argument('-s','--seed',dest='seed',help='Random seed',type=int,default=None)
    parser.add_argument('-r','--rep',dest='rep',help='Training replicate number',type=int,default=None)
    parser.add_argument('-t','--nCPU',dest='nCPU',help='Number of CPUs to use',type=int,default=1)
    parser.add_argument('--gpuID',dest='gpuID',help='Identifier specifying which GPU to use', type=int, default=0)
    args = parser.parse_args()
    
    
    ### Set seed
    if args.seed:
        os.environ['PYTHONHASHSEED']=str(args.seed)
        random.seed(args.seed)
        np.random.seed(args.seed)
        tf.random.set_seed(args.seed)
        os.environ['TF_DETERMINISTIC_OPS'] = '1'
        os.environ['TF_CUDNN_DETERMINISTIC'] = '1'

    
    #### Shuffle files and directories around
    ### rename Dir_B sfs.pdf
    #cmd = "mv %s %s" %(os.path.join(args.outDir_B,"networks","testSet_sfs.pdf"), os.path.join(args.outDir_B,"networks","testSet_B_sfs.pdf"))
    #os.system(cmd)
    ### Copy contents of networks directory from Dir_A to Dir_B
    #print("Copying contents of Dir_A/networks to Dir_B/networks")
    #cmd = "cp -r %s %s" %(os.path.join(args.outDir_A,"networks"), args.outDir_B)
    #os.system(cmd)
    #cmd = "mv %s %s" %(os.path.join(args.outDir_B,"networks","testSet_sfs.pdf"), os.path.join(args.outDir_B,"networks","testSet_A_sfs.pdf"))
    #os.system(cmd)

    ## Set up the directory structure to store the simulations data.
    
    trainDir = os.path.join(projectDir_A,"train")
    trainDirB = os.path.join(projectDir_B,"train")
    valiDir = os.path.join(projectDir_A,"vali")
    valiDirB = os.path.join(projectDir_B,"vali")
    testDir = os.path.join(projectDir_B,"test")
    networkDir = os.path.join(projectDir_B,"networks")


    ## Define output files
    test_resultFile = os.path.join(networkDir,"testResults.p")
    test_resultFig = os.path.join(networkDir,"testResults.pdf")
    modelSave = os.path.join(networkDir,"model.json")
    weightsSave = os.path.join(networkDir,"weights.h5")


    ## Identify padding required
    ## using the option 0 will trim all tensors to the length of the tensor with the fewest sites
    maxSegSites = float("inf")
    if args.maxSegSites == 0:
        for nDir in [trainDir,valiDir]:
            S_min = min(pickle.load(open(os.path.join(nDir,"info.p"),"rb"))["segSites"])
            maxSegSites = min(maxSegSites, S_min)
    else:
        maxSegSites = args.maxSegSites
    
    
    ## Set network parameters
    bds_train_params = {
        'treesDirectory':trainDir,
        'targetNormalization':"zscore",
        'batchSize': 64,
        'maxLen': maxSegSites,
        'frameWidth': 0,
        'shuffleInds':True,
        'sortInds':False,
        'center':False,
        'ancVal':0,
        'padVal':0,
        'derVal':1,
        'realLinePos':True,
        'posPadVal':0,
        'seqD':None,
        'randN':args.seed
              }


    ## Dump batch pars for bootstrap
    batchParsFILE=os.path.join(networkDir,"batchPars.p")
    with open(batchParsFILE, "wb") as fOUT:
        pickle.dump(bds_train_params,fOUT)


    bds_vali_params = copy.deepcopy(bds_train_params)
    bds_vali_params['treesDirectory'] = valiDir
    bds_vali_params['batchSize'] = 64

    bds_test_params = copy.deepcopy(bds_train_params)
    bds_test_params['treesDirectory'] = testDir
    test_info = pickle.load(open(os.path.join(testDir,"info.p"),"rb"))
    bds_test_params['batchSize'] = test_info["numReps"]
    bds_test_params['shuffleExamples'] = False


    ## Define sequence batch generator
    train_sequence = SequenceBatchGenerator(**bds_train_params)
    vali_sequence = SequenceBatchGenerator(**bds_vali_params)
    test_sequence = SequenceBatchGenerator(**bds_test_params)

    
    ## Train network
    runModels_cleverhans_tf2_B(ModelFuncPointer=iaiGRU_categorical_crossentropy_noPos,
            ModelName="iaiGRU_categorical_crossentropy_noPos",
            NetworkDir=networkDir,
            ProjectDir=projectDir_B,
            TrainGenerator=train_sequence,
            ValidationGenerator=vali_sequence,
            TestGenerator=test_sequence,
            test_info=test_info,
            resultsFile=test_resultFile,
            init=args.weights,
            network=[modelSave,weightsSave],
            numEpochs=args.nEpochs,
            validationSteps=args.nValSteps,
            nCPU=args.nCPU,
            gpuID=args.gpuID,
            learningRate=0.001)


    ## Plot results of predictions on test set
    plotResultsSoftmax2HeatmapMis(resultsFile=test_resultFile, resultsFile2=test_resultFile.replace(".p","_fgsm.p"), saveas=test_resultFig.replace(".pdf","_fgsm_compared.pdf"))
    #plotResultsSoftmax2HeatmapMis(resultsFile=test_resultFile, resultsFile2=test_resultFile.replace(".p","_pgd.p"), saveas=test_resultFig.replace(".pdf","_pgd_compared.pdf"))
    #plotSummaryStats(projectDir_A=projectDir_A, projectDir_B=projectDir_B, saveas=test_resultFig.replace(".pdf","_stats.pdf"))
    
    ## remove train and vali directories

    print("\n***FINISHED!***\n")
    #shutil.rmtree(trainDirB)
    #shutil.rmtree(trainDirB_fgsm)
    #shutil.rmtree(trainDirB_pgd)
    #shutil.rmtree(valiDirB)
    #shutil.rmtree(valiDirB_fgsm)
    #shutil.rmtree(valiDirB_pgd)


if __name__ == "__main__":
	main()
