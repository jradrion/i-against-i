#!/usr/bin/env python
from iai.imports import *
from iai.helpers import *
from iai.sequenceBatchGenerator import *
from iai.networks import *
from iai.trainer import *


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('-d','--projectDir',dest='outDir',help='Directory for all project output. NOTE: the same projectDir must be used for all functions of i-against-i',default=None)
    parser.add_argument('--adaptive',help='use adaptive training instead of adversarial training',default=False, action='store_true')
    parser.add_argument('--paramsID',help='paramsID',type=int,default=None)
    parser.add_argument('-m','--maxSegSites',dest='maxSegSites',help='All tensors exceeding this length with be trimmed', type=int, default=1000)
    parser.add_argument('--fgsm',dest='fgsm',help='Train on FGSM attacked examples',default=False,action='store_true')
    parser.add_argument('--pgd',dest='pgd',help='Train on PGD attacked examples',default=False,action='store_true')
    parser.add_argument('--cnn',dest='cnn',help='Train using a 1D CNN',default=False,action='store_true')
    parser.add_argument('--gru',dest='gru',help='Train using a bidirectinal GRU',default=False,action='store_true')
    parser.add_argument('-w','--initWeights',dest='weights',help='Path to the initialization weights',default=None)
    parser.add_argument('--nEpochs',dest='nEpochs',help='Maximum number of epochs to train (EarlyStopping is implemented for validation accuracy)', type=int, default=1000)
    parser.add_argument('--nValSteps',dest='nValSteps',help='Number of validation steps', type=int, default=20)
    parser.add_argument('-s','--seed',dest='seed',help='Random seed',type=int,default=None)
    parser.add_argument('-r','--rep',dest='rep',help='Training replicate number',type=int,default=None)
    parser.add_argument('-t','--nCPU',dest='nCPU',help='Number of CPUs to use',type=int,default=1)
    parser.add_argument('--gpuID',dest='gpuID',help='Identifier specifying which GPU to use', type=int, default=0)
    args = parser.parse_args()
    
    
    ### Set seed
    if args.seed:
        os.environ['PYTHONHASHSEED']=str(args.seed)
        random.seed(args.seed)
        np.random.seed(args.seed)
        tf.random.set_seed(args.seed)
        os.environ['TF_DETERMINISTIC_OPS'] = '1'
        os.environ['TF_CUDNN_DETERMINISTIC'] = '1'


    ## Set up the directory structure to store the simulations data.
    projectDir = args.outDir
    if args.rep:
        trainDir = os.path.join(projectDir,"train")
        valiDir = os.path.join(projectDir,"vali")
        testDir = os.path.join(projectDir,"test_params%s"%(args.paramsID))
        networkDir = os.path.join(projectDir,"networks_rep%s"%(args.rep))
    else:
        trainDir = os.path.join(projectDir,"train")
        valiDir = os.path.join(projectDir,"vali")
        testDir = os.path.join(projectDir,"test_params%s"%(args.paramsID))
        networkDir = os.path.join(projectDir,"networks")

    admixture=pickle.load(open(os.path.join(networkDir,"simPars.p"), "rb"))["admixture"]

    ## Define output files
    test_resultFile = os.path.join(networkDir,"testResults.p")
    test_resultFig = os.path.join(networkDir,"testResults.pdf")
    modelSave = os.path.join(networkDir,"model.json")
    weightsSave = os.path.join(networkDir,"weights.h5")


    ## Identify padding required
    ## using the option 0 will trim all tensors to the length of the tensor with the fewest sites
    maxSegSites = float("inf")
    if args.maxSegSites == 0:
        for nDir in [trainDir,valiDir]:
            S_min = min(pickle.load(open(os.path.join(nDir,"info.p"),"rb"))["segSites"])
            maxSegSites = min(maxSegSites, S_min)
    else:
        maxSegSites = args.maxSegSites
    
    
    ## Set network parameters
    bds_train_params = {
        'treesDirectory':trainDir,
        'targetNormalization':"zscore",
        'batchSize': 64,
        'maxLen': maxSegSites,
        'frameWidth': 0,
        'shuffleInds':True,
        'sortInds':False,
        'center':False,
        'ancVal':0,
        'padVal':0,
        'derVal':1,
        'realLinePos':True,
        'posPadVal':0,
        'seqD':None}


    ## Dump batch pars for bootstrap
    batchParsFILE=os.path.join(networkDir,"batchPars.p")
    with open(batchParsFILE, "wb") as fOUT:
        pickle.dump(bds_train_params,fOUT)


    bds_vali_params = copy.deepcopy(bds_train_params)
    bds_vali_params['treesDirectory'] = valiDir
    bds_vali_params['batchSize'] = 64

    bds_test_params = copy.deepcopy(bds_train_params)
    bds_test_params['treesDirectory'] = testDir
    test_info = pickle.load(open(os.path.join(testDir,"info.p"),"rb"))
    bds_test_params['batchSize'] = test_info["numReps"]
    bds_test_params['shuffleExamples'] = False


    ## Define sequence batch generator
    train_sequence = SequenceBatchGenerator(**bds_train_params)
    vali_sequence = SequenceBatchGenerator(**bds_vali_params)
    test_sequence = SequenceBatchGenerator(**bds_test_params)

    
    ## Train network
    if args.gru:
        mfp=iaiGRU_categorical_crossentropy_noPos
        mn="iaiGRU_categorical_crossentropy_noPos"
    if args.cnn:
        mfp=iaiCNN_categorical_crossentropy_noPos
        mn="iaiCNN_categorical_crossentropy_noPos"
    if args.adaptive:
        predict_adaptive(ModelFuncPointer=mfp,
                ModelName=mn,
                NetworkDir=networkDir,
                ProjectDir=projectDir,
                TrainGenerator=train_sequence,
                ValidationGenerator=vali_sequence,
                TestGenerator=test_sequence,
                test_info=test_info,
                resultsFile=test_resultFile,
                init=args.weights,
                network=[modelSave,weightsSave],
                numEpochs=args.nEpochs,
                validationSteps=args.nValSteps,
                nCPU=args.nCPU,
                gpuID=args.gpuID,
                paramsID=args.paramsID,
                admixture=admixture)
    else:
        predict_cleverhans_tf2(ModelFuncPointer=mfp,
                ModelName=mn,
                NetworkDir=networkDir,
                ProjectDir=projectDir,
                TrainGenerator=train_sequence,
                ValidationGenerator=vali_sequence,
                TestGenerator=test_sequence,
                test_info=test_info,
                resultsFile=test_resultFile,
                init=args.weights,
                network=[modelSave,weightsSave],
                numEpochs=args.nEpochs,
                validationSteps=args.nValSteps,
                nCPU=args.nCPU,
                gpuID=args.gpuID,
                paramsID=args.paramsID,
                FGSM=args.fgsm,
                PGD=args.pgd)


        ## Plot results of predictions on test set
        file1 = test_resultFile.replace(".p","_params%s.p"%(args.paramsID))
        if args.fgsm:
            plotResultsSoftmax2HeatmapMis(resultsFile=file1, resultsFile2=test_resultFile.replace(".p","_fgsm_params%s.p"%(args.paramsID)), saveas=test_resultFig.replace(".pdf","_fgsm_params%s.pdf"%(args.paramsID)),admixture=admixture)
        if args.pgd:
            plotResultsSoftmax2HeatmapMis(resultsFile=file1, resultsFile2=test_resultFile.replace(".p","_pgd_params%s.p"%(args.paramsID)), saveas=test_resultFig.replace(".pdf","_pgd_params%s.pdf"%(args.paramsID)),admixture=admixture)
        #plotSummaryStats(projectDir_A=projectDir_A, projectDir_B=projectDir_B, saveas=test_resultFig.replace(".pdf","_stats.pdf"))
    
    print("\n***FINISHED!***\n")


if __name__ == "__main__":
	main()
