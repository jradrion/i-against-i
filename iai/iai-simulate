#!/usr/bin/env python

from iai.imports import *
from iai.helpers import *
from iai.manager import *
from iai.simulator import *


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('-d','--projectDir',dest='outDir',help='Directory for all project output. NOTE: the same projectDir must be used for all functions of i-against-i',default=None)
    parser.add_argument('-u_lo','--assumedMu_lo',dest='mu_lo',help='Lower bound of assumed per-base mutation rate',type=float,default=1e-8)
    parser.add_argument('-u_hi','--assumedMu_hi',dest='mu_hi',help='Upper bound of assumed per-base mutation rate',type=float,default=1e-8)
    parser.add_argument('-r_lo','--assumedR_lo',dest='r_lo',help='Lower bound of assumed per-base recombination rate',type=float,default=1e-8)
    parser.add_argument('-r_hi','--assumedR_hi',dest='r_hi',help='Upper bound of assumed per-base recombination rate',type=float,default=1e-8)
    parser.add_argument('-gr_lo','--assumedGr_lo',dest='gr_lo',help='Lower bound of assumed population size growth rate',type=float,default=0.004)
    parser.add_argument('-gr_hi','--assumedGr_hi',dest='gr_hi',help='Upper bound of assumed population size growth rate',type=float,default=0.004)
    parser.add_argument('-ne_lo','--assumedNe_lo',dest='ne_lo',help='Lower bound of assumed effective population size',type=float,default=0.004)
    parser.add_argument('-ne_hi','--assumedNe_hi',dest='ne_hi',help='Upper bound of assumed effective population size',type=float,default=0.004)
    parser.add_argument('-f','--fractionGrowth',dest='fGrowth',help='Fraction of training examples that will be simulated under a model of  exponential growth',type=float,default=0.5)
    parser.add_argument('--cLen',dest='cLen',help='Length of chromosome to simulate',type=int,default=1000000)
    parser.add_argument('--sam',dest='sam',help='sample size',type=int,default=10)
    parser.add_argument('-s','--seed',dest='seed',help='Random seed',type=int,default=None)
    parser.add_argument('-t','--nCPU',dest='nCPU',help='Number of CPUs to use',type=int,default=1)
    parser.add_argument('--phased',help='Treat genotypes as phased',default=False, action='store_true')
    parser.add_argument('--unphased',dest='phased',help='Treat genotypes as unphased',action='store_false')
    parser.add_argument('--nTrain',dest='nTrain',help='Number of training examples to simulate',type=int,default=100000)
    parser.add_argument('--nVali',dest='nVali',help='Number of validation examples to simulate',type=int,default=1000)
    parser.add_argument('--nTest',dest='nTest',help='Number of test examples to simulate',type=int,default=1000)
    args = parser.parse_args()
    
    # Ensure all required arguments are provided
    if not args.outDir:
        print("Warning: No project directory found, using current working directory.")
        projectDir = os.getcwd()
    else:
        projectDir = args.outDir
    
    ## Set seed
    if args.seed:
        random.seed(args.seed)
        np.random.seed(args.seed)
        tf.random.set_seed(args.seed)
 
    ## Set up the directory structure to store the simulations data.
    nProc = args.nCPU
    trialDir = os.path.join(projectDir,"trial")
    trainDir = os.path.join(projectDir,"train")
    valiDir = os.path.join(projectDir,"vali")
    testDir = os.path.join(projectDir,"test")
    networkDir = os.path.join(projectDir,"networks")


    ## Make directories if they do not exist
    for p in [projectDir,trialDir,trainDir,valiDir,testDir,networkDir]:
        if not os.path.exists(p):
            os.makedirs(p)

    assumedMu_lo = args.mu_lo
    assumedMu_hi = args.mu_hi
    assumedR_lo = args.r_lo
    assumedR_hi = args.r_hi
    assumedGr_lo = args.gr_lo
    assumedGr_hi = args.gr_hi
    assumedNe_lo = args.ne_lo
    assumedNe_hi = args.ne_hi
    nSamps = args.sam
    cLen = args.cLen
    
    dg_params = {'N':nSamps,
        'Ne_growth_lo':assumedNe_lo,
        'Ne_growth_hi':assumedNe_hi,
        'priorLowsRho':assumedR_lo,
        'priorHighsRho':assumedR_hi,
        'priorLowsMu':assumedMu_lo,
        'priorHighsMu':assumedMu_hi,
        'priorLowsGr':assumedGr_lo,
        'priorHighsGr':assumedGr_hi,
        'ChromosomeLength':cLen,
        'winMasks':None,
        'maskThresh':None,
        'phased':args.phased,
        'fractionGrowth': 1,
        'seed':args.seed
              }

    # Assign pars for each simulation
    dg_trial = Simulator(**dg_params)
    
    print("\nDetermine relative Ne for simulations with and without growth...")
    dg_trial.simulateAndProduceTrees(numReps=args.nTrain,direc=trialDir,simulator="msprime",nProc=nProc)
    
    DsInfoDir = pickle.load(open(os.path.join(trialDir,"info.p"),"rb"))
    S = DsInfoDir["segSites"]
    a=0
    for i in range(nSamps-1):
        a+=1/(i+1)
    thetaW=np.average(S)/float(a)
    Ne_fromTheta=int(thetaW/(4.0 * np.mean([assumedMu_lo,assumedMu_hi]) * cLen))
    
    
    print("Ne inferred from thetaW:",Ne_fromTheta)
    

    dg_params = {'N':nSamps,
        'Ne_growth_lo':assumedNe_lo,
        'Ne_growth_hi':assumedNe_hi,
        'Ne_noGrowth':Ne_fromTheta,
        'priorLowsRho':assumedR_lo,
        'priorHighsRho':assumedR_hi,
        'priorLowsMu':assumedMu_lo,
        'priorHighsMu':assumedMu_hi,
        'priorLowsGr':assumedGr_lo,
        'priorHighsGr':assumedGr_hi,
        'ChromosomeLength':cLen,
        'winMasks':None,
        'maskThresh':None,
        'phased':args.phased,
        'fractionGrowth': args.fGrowth,
        'seed':args.seed
              }
    
    # Assign pars for each simulation
    dg_train = Simulator(**dg_params)
    dg_vali = Simulator(**dg_params)
    dg_test = Simulator(**dg_params)

    ## Dump simulation pars for use with parametric bootstrap
    simParsFILE=os.path.join(networkDir,"simPars.p")
    with open(simParsFILE, "wb") as fOUT:
        dg_params["bn"]=os.path.basename(projectDir)
        pickle.dump(dg_params,fOUT)

    ## Simulate data
    print("\nTraining set:")
    dg_train.simulateAndProduceTrees(numReps=args.nTrain,direc=trainDir,simulator="msprime",nProc=nProc)
    print("Validation set:")
    dg_vali.simulateAndProduceTrees(numReps=args.nVali,direc=valiDir,simulator="msprime",nProc=nProc)
    print("Test set:")
    dg_test.simulateAndProduceTrees(numReps=args.nTest,direc=testDir,simulator="msprime",nProc=nProc)
    print("\nSIMULATIONS FINISHED!\n")
    
    
    ## Count number of segregating sites in simulation
    SS=[]
    maxSegSites = 0
    minSegSites = float("inf")
    #for ds in [trainDir,valiDir,testDir,testDirLo,testDirHi]:
    for ds in [trainDir,valiDir,testDir]:
        DsInfoDir = pickle.load(open(os.path.join(ds,"info.p"),"rb"))
        SS.extend(DsInfoDir["segSites"])
        segSitesInDs = max(DsInfoDir["segSites"])
        segSitesInDsMin = min(DsInfoDir["segSites"])
        maxSegSites = max(maxSegSites,segSitesInDs)
        minSegSites = min(minSegSites,segSitesInDsMin)
    ## Compare counts of segregating sites between simulations and input VCF
    print("SANITY CHECK")
    print("====================")
    print("numSegSites\t\t\tMin\tMean\tMax")
    print("Simulated:\t\t\t%s\t%s\t%s" %(minSegSites, int(sum(SS)/float(len(SS))), maxSegSites))
    print("\n\n***FINISHED***\n")
    

    ## Plot the SFS of the test set
    outfile = os.path.join(networkDir, "testSet_sfs.pdf") 
    sfs_const, sfs_expan = [], []
    pi_const, pi_expan = [], []
    info = pickle.load(open(os.path.join(testDir,"info.p"),"rb"))
    gr = info["gr"]
    for i, rate in enumerate(gr):
        Hfilepath = os.path.join(testDir,str(i) + "_haps.npy")
        Pfilepath = os.path.join(testDir,str(i) + "_pos.npy")
        H = np.load(Hfilepath)
        P = np.load(Pfilepath)
        ac = allel.HaplotypeArray(H).count_alleles()
        pi = allel.sequence_diversity(P,ac)
        rawSFS = allel.sfs(ac[:, 1], n=H.shape[1])[1:]
        relSFS = np.divide(rawSFS,sum(rawSFS))
        if rate > 0.0:
            sfs_expan.append(relSFS)
            pi_expan.append(pi)
        else:
            sfs_const.append(relSFS)
            pi_const.append(pi)
    sfs_const_avg = np.mean(np.array(sfs_const),axis=0)
    sfs_expan_avg = np.mean(np.array(sfs_expan),axis=0)
    s = [sfs_const_avg, sfs_expan_avg]
    bins = [n + 1 for n in range(len(s[0]))]
    vals = []
    for i in range(len(s)):
        vals.append([x for x in s[i]])
    f, ax = plt.subplots(1, 2, sharey=True, tight_layout=True, figsize=(8, 3))
    ax[0].bar(bins, vals[0])
    ax[1].bar(bins, vals[1])
    ax[0].set_title("Constant size (pi = %s)" %(round(np.mean(pi_const),5)))
    ax[1].set_title("Exponential growth (pi = %s)" %(round(np.mean(pi_expan),5)))
    ax[0].set_ylabel("Counts (percent)")
    ax[0].set_xlabel("Derived allele frequency")
    ax[1].set_xlabel("Derived allele frequency")
    f.savefig(outfile, bbox_inches='tight')
    plt.close()

    ## remove trial directory
    shutil.rmtree(trialDir)

if __name__ == "__main__":
	main()
